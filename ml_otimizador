from dataclasses import dataclass
from typing import Optional
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

@dataclass
class MLConfig:
    test_size: float = 0.3
    random_state: int = 42
    n_estimators: int = 200
    max_depth: Optional[int] = None

@dataclass
class MLResult:
    model: RandomForestClassifier
    accuracy: float
    report_text: str
    feature_importances: pd.DataFrame

def train_random_forest_from_features(
    df: pd.DataFrame,
    label_col: str = "label",
    config: Optional[MLConfig] = None,
) -> MLResult:

    if config is None:
        config = MLConfig()

    y = df[label_col]
    X = df.drop(columns=[label_col])

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=config.test_size,
        random_state=config.random_state,
        stratify=y if y.nunique() > 1 else None,
    )

    model = RandomForestClassifier(
        n_estimators=config.n_estimators,
        max_depth=config.max_depth,
        random_state=config.random_state,
        n_jobs=-1,
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    importances = pd.DataFrame({
        "feature": X.columns,
        "importance": model.feature_importances_,
    }).sort_values("importance", ascending=False)

    return MLResult(model, acc, report, importances)
