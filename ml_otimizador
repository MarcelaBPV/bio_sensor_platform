# ml_otimizador.py
# -*- coding: utf-8 -*-
"""
Módulo de otimização / aprendizado de máquina para o BioRaman.

Responsabilidades:
- Transformar tabela de picos Raman em matriz de features
- Treinar modelo de classificação (Random Forest)
- Retornar métricas e importâncias de features

Este módulo é genérico o suficiente para ser usado na Aba 3 do app Streamlit.
"""

from dataclasses import dataclass
from typing import Tuple, Optional, Dict, Any

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report


# ----------------------------------------------------------------------
# 1) Configuração do modelo (hiperparâmetros)
# ----------------------------------------------------------------------

@dataclass
class MLConfig:
    """
    Configurações para o modelo Random Forest.
    """
    test_size: float = 0.3
    random_state: int = 42
    n_estimators: int = 200
    max_depth: Optional[int] = None
    min_samples_split: int = 2
    min_samples_leaf: int = 1


@dataclass
class MLResult:
    """
    Resultado completo do treinamento de modelo.
    """
    model: RandomForestClassifier
    X_train: pd.DataFrame
    X_test: pd.DataFrame
    y_train: pd.Series
    y_test: pd.Series
    report_text: str
    feature_importances_: pd.DataFrame


# ----------------------------------------------------------------------
# 2) Construção de features a partir de picos
# ----------------------------------------------------------------------

def build_group_features(
    peaks_df: pd.DataFrame,
    id_col: str = "sample_id",
    label_col: str = "label",
    group_col: str = "grupo_molecular",
    intensity_col: str = "intensidade",
    agg_fn: str = "max",
) -> Tuple[pd.DataFrame, pd.Series]:
    """
    Constrói uma matriz de features a partir de uma tabela de picos.

    Espera um DataFrame com, no mínimo, as colunas:
    - id_col         : identificador da amostra (ex.: 'patient_id' ou 'sample_id')
    - label_col      : rótulo da amostra (ex.: tipo de doença, classe, etc.)
    - group_col      : grupo molecular associado ao pico (ex.: 'Hemoglobina / porfirinas')
    - intensity_col  : intensidade do pico naquele grupo

    Estratégia:
    - Para cada (amostra, grupo_molecular) agrega a intensidade (max, mean, etc.)
    - Faz pivot: linhas = amostras, colunas = grupos, valores = intensidade agregada

    Retorna:
    - X: DataFrame de features (uma linha por amostra)
    - y: Series de rótulos (mesmo índice de X)
    """
    required_cols = {id_col, label_col, group_col, intensity_col}
    missing = required_cols.difference(peaks_df.columns)
    if missing:
        raise ValueError(
            f"Faltam colunas obrigatórias em peaks_df: {missing}. "
            f"Esperado pelo menos: {required_cols}"
        )

    # Filtra apenas colunas relevantes
    df = peaks_df[[id_col, label_col, group_col, intensity_col]].copy()

    # Agregação: ex. max intensidade por (amostra, grupo)
    if agg_fn == "max":
        agg_df = df.groupby([id_col, group_col], as_index=False)[intensity_col].max()
    elif agg_fn == "mean":
        agg_df = df.groupby([id_col, group_col], as_index=False)[intensity_col].mean()
    else:
        raise ValueError("agg_fn deve ser 'max' ou 'mean'.")

    # Pivot: uma coluna por grupo molecular
    features = agg_df.pivot_table(
        index=id_col,
        columns=group_col,
        values=intensity_col,
        fill_value=0.0,
    )

    # Rótulos (label) – assume-se 1 label por amostra
    labels = (
        df[[id_col, label_col]]
        .drop_duplicates(subset=[id_col])
        .set_index(id_col)[label_col]
        .reindex(features.index)
    )

    # Garante tipo numérico
    features = features.astype(float)

    return features, labels


# ----------------------------------------------------------------------
# 3) Treinamento de Random Forest
# ----------------------------------------------------------------------

def train_random_forest(
    X: pd.DataFrame,
    y: pd.Series,
    config: Optional[MLConfig] = None,
) -> MLResult:
    """
    Treina um modelo Random Forest para classificação de amostras de sangue
    a partir de features derivadas dos picos Raman.

    Parâmetros:
    - X: DataFrame com features numéricas (linhas = amostras)
    - y: Series com o rótulo de cada amostra
    - config: MLConfig com hiperparâmetros do modelo e split train/test

    Retorna:
    - MLResult com modelo, splits e métricas
    """
    if config is None:
        config = MLConfig()

    # Remove amostras com label ausente
    mask_valid = y.notna()
    X = X.loc[mask_valid]
    y = y.loc[mask_valid]

    X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        test_size=config.test_size,
        random_state=config.random_state,
        stratify=y if len(y.unique()) > 1 else None,
    )

    model = RandomForestClassifier(
        n_estimators=config.n_estimators,
        max_depth=config.max_depth,
        min_samples_split=config.min_samples_split,
        min_samples_leaf=config.min_samples_leaf,
        random_state=config.random_state,
        n_jobs=-1,
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    report_text = classification_report(y_test, y_pred)

    # Importância das features (grupos moleculares)
    importances = pd.DataFrame(
        {
            "feature": X.columns,
            "importance": model.feature_importances_,
        }
    ).sort_values("importance", ascending=False)

    return MLResult(
        model=model,
        X_train=X_train,
        X_test=X_test,
        y_train=y_train,
        y_test=y_test,
        report_text=report_text,
        feature_importances_=importances,
    )


# ----------------------------------------------------------------------
# 4) Função auxiliar para uso no Streamlit (Aba 3)
# ----------------------------------------------------------------------

def run_ml_pipeline_from_peaks_table(
    peaks_df: pd.DataFrame,
    config: Optional[MLConfig] = None,
    id_col: str = "sample_id",
    label_col: str = "label",
    group_col: str = "grupo_molecular",
    intensity_col: str = "intensidade",
) -> Dict[str, Any]:
    """
    Função "tudo em um" pensada para ser chamada na Aba 3 do Streamlit.

    1) Constrói features a partir da tabela de picos (build_group_features)
    2) Treina Random Forest (train_random_forest)
    3) Retorna um dicionário pronto para ser usado na interface:

       {
         "X": X,
         "y": y,
         "ml_result": MLResult,
       }
    """
    X, y = build_group_features(
        peaks_df=peaks_df,
        id_col=id_col,
        label_col=label_col,
        group_col=group_col,
        intensity_col=intensity_col,
    )

    ml_result = train_random_forest(X, y, config=config)

    return {
        "X": X,
        "y": y,
        "ml_result": ml_result,
    }
